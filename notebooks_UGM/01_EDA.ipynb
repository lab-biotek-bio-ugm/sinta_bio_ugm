{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e30a41-56f0-48f0-96c2-df52e344e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2456fa-b2d6-4263-93b8-6ff95f1dd347",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 400\n",
    "HEIGHT = 400\n",
    "N_CLUSTER = 12\n",
    "SELECTION = 'cluster'\n",
    "SELECTION_LABEL = 'Cluster'\n",
    "AFFILIATIONS = [\"UGM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96af992-dca9-4124-b6d1-49cbcfe1f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/UGM_BIO/biology.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda78bcb-c368-4ff1-a43d-759908da92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vis = {}\n",
    "ctr = 0\n",
    "for sinta_id, value in data.items():\n",
    "    name = value[\"name_inputted\"]\n",
    "    for item in value['publications']:\n",
    "        text_vis[ctr] = {\"author\": sinta_id,\n",
    "                         \"title\" : item['bib']['title']}\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92930ee9-eaad-42cd-8e3c-8731e5840172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(text_vis).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417aca27-8b01-4307-80cc-71d08ba692eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the most common words per cluster\n",
    "def get_top_words(titles, stop_words='english', top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    tfidf_matrix = vectorizer.fit_transform(titles)\n",
    "    feature_array = vectorizer.get_feature_names_out()\n",
    "    tfidf_sorting = tfidf_matrix.toarray().sum(axis=0).argsort()[::-1]\n",
    "    top_words = [feature_array[i] for i in tfidf_sorting[:top_n]]\n",
    "    return top_words\n",
    "\n",
    "# Combine English and Indonesian stop words\n",
    "indonesian_stop_words = [\n",
    "    'dan', 'yang', 'untuk', 'dari', 'dengan', 'pada', 'adalah', 'ke', 'di', 'sebagai', 'ini',\n",
    "    'itu', 'oleh', 'dalam', 'atau', 'juga', 'tersebut', 'sangat', 'agar', 'bisa', 'karena', 'terhadap',\n",
    "    'pengaruh', 'berdasarkan', 'indonesia', 'isolated', 'based', 'daerah', 'indonesian', 'yogyakarta',\n",
    "    'java', 'analysis', 'effect', 'using', \"sp\"\n",
    "]\n",
    "english_stop_words = set(TfidfVectorizer(stop_words='english').get_stop_words())\n",
    "combined_stop_words = list(english_stop_words.union(indonesian_stop_words))\n",
    "\n",
    "# Step 1: Text Preprocessing and Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words=combined_stop_words)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['title'])\n",
    "\n",
    "# Step 2: Aggregation\n",
    "# Combine all titles for each author into a single string\n",
    "author_profiles = df.groupby('author')['title'].apply(lambda titles: ' '.join(titles)).reset_index()\n",
    "author_tfidf_matrix = vectorizer.transform(author_profiles['title'])\n",
    "\n",
    "# Step 3: Dimensionality Reduction (optional)\n",
    "pca = PCA(n_components=3)\n",
    "reduced_tfidf_matrix = pca.fit_transform(author_tfidf_matrix.toarray())\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7702c-5b83-47c4-bb28-6142763f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate metrics for a range of k values\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "box_size = 150\n",
    "font_size = 10\n",
    "\n",
    "for k in range(2, 21):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(reduced_tfidf_matrix)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(reduced_tfidf_matrix, clusters))\n",
    "    davies_bouldin_scores.append(davies_bouldin_score(reduced_tfidf_matrix, clusters))\n",
    "\n",
    "# Create dataframes for plotting\n",
    "wcss_df = pd.DataFrame({'k': range(2, 21), 'WCSS': wcss})\n",
    "silhouette_df = pd.DataFrame({'k': range(2, 21), 'Silhouette Score': silhouette_scores})\n",
    "davies_bouldin_df = pd.DataFrame({'k': range(2, 21), 'Davies-Bouldin Index': davies_bouldin_scores})\n",
    "\n",
    "# Plot the Elbow Method results\n",
    "elbow_plot = alt.Chart(wcss_df).mark_line(point=True).encode(\n",
    "    x=alt.X('k', title='Number of Clusters (k)', axis=alt.Axis(labelFontSize=font_size, titleFontSize=font_size)),\n",
    "    y=alt.Y('WCSS', title='WCSS', axis=alt.Axis(labelFontSize=font_size, titleFontSize=font_size)),\n",
    "    tooltip=['k', 'WCSS']\n",
    ").properties(\n",
    "    title=alt.TitleParams('Elbow Method for Optimal k', fontSize=font_size+2),\n",
    "    height=box_size,\n",
    "    width=box_size\n",
    ")\n",
    "\n",
    "# Plot the Silhouette Score results\n",
    "silhouette_plot = alt.Chart(silhouette_df).mark_line(point=True).encode(\n",
    "    x=alt.X('k', title='Number of Clusters (k)', axis=alt.Axis(labelFontSize=font_size, titleFontSize=font_size)),\n",
    "    y=alt.Y('Silhouette Score', title='Silhouette Score', axis=alt.Axis(labelFontSize=font_size, titleFontSize=font_size)),\n",
    "    tooltip=['k', 'Silhouette Score']\n",
    ").properties(\n",
    "    title=alt.TitleParams('Silhouette Score for Optimal k', fontSize=font_size+2),\n",
    "    height=box_size,\n",
    "    width=box_size\n",
    ")\n",
    "\n",
    "# Plot the Davies-Bouldin Index results\n",
    "davies_bouldin_plot = alt.Chart(davies_bouldin_df).mark_line(point=True).encode(\n",
    "    x=alt.X('k', title='Number of Clusters (k)', axis=alt.Axis(labelFontSize=font_size, titleFontSize=font_size)),\n",
    "    y=alt.Y('Davies-Bouldin Index', title='Davies-Bouldin Index', axis=alt.Axis(labelFontSize=font_size, titleFontSize=font_size)),\n",
    "    tooltip=['k', 'Davies-Bouldin Index']\n",
    ").properties(\n",
    "    title=alt.TitleParams('Davies-Bouldin Index for Optimal k', fontSize=font_size+2),\n",
    "    height=box_size,\n",
    "    width=box_size\n",
    ")\n",
    "\n",
    "# Display the plots\n",
    "cluster_plot = (elbow_plot | silhouette_plot | davies_bouldin_plot)\n",
    "\n",
    "outfile = Path(\"../figures/01_clusterplot_publication_titles.html\")\n",
    "outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "cluster_plot.save(outfile)\n",
    "cluster_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a677e9-73ac-4bd5-ad72-3842ad4fadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Clustering\n",
    "num_clusters = N_CLUSTER\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "clusters = kmeans.fit_predict(reduced_tfidf_matrix)\n",
    "\n",
    "# Adding cluster labels to the DataFrame\n",
    "author_profiles['cluster'] = clusters\n",
    "author_profiles['PCA1'] = reduced_tfidf_matrix[:, 0]\n",
    "author_profiles['PCA2'] = reduced_tfidf_matrix[:, 1]\n",
    "\n",
    "# Step 5: Evaluation\n",
    "silhouette_avg = silhouette_score(reduced_tfidf_matrix, clusters)\n",
    "\n",
    "# Step 6: Enrich the DataFrame using the mapping dictionary\n",
    "author_profiles['author_name'] = author_profiles['author'].apply(lambda x: data[x]['name_inputted'])\n",
    "author_profiles['subjects'] = author_profiles['author'].apply(lambda x: \", \".join(data[x]['subjects']))\n",
    "author_profiles['sinta_id'] = author_profiles['author']\n",
    "author_profiles['affiliation_sinta'] = author_profiles['author'].apply(lambda x: data[x]['affiliation_sinta']['name'])\n",
    "\n",
    "# Step 7: Visualization with Altair\n",
    "\n",
    "# Get the most common words for each cluster\n",
    "cluster_words = {}\n",
    "for cluster in author_profiles['cluster'].unique():\n",
    "    titles = author_profiles[author_profiles['cluster'] == cluster]['title']\n",
    "    top_words = get_top_words(titles, stop_words=combined_stop_words, top_n=5)\n",
    "    cluster_words[cluster] = ', '.join(top_words)\n",
    "\n",
    "author_words = {}\n",
    "for author in author_profiles['author'].unique():\n",
    "    titles = author_profiles[author_profiles['author'] == author]['title']\n",
    "    top_words = get_top_words(titles, stop_words=combined_stop_words, top_n=5)\n",
    "    author_words[author] = ', '.join(top_words)\n",
    "\n",
    "# Visualization with Altair\n",
    "author_profiles['top_words_author'] = author_profiles['author'].apply(lambda x: author_words[x])\n",
    "author_profiles['top_words_cluster'] = author_profiles['cluster'].apply(lambda x: cluster_words[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c984db-de7a-456f-88d5-921c1b95d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [i for i in author_profiles[SELECTION].unique()]\n",
    "\n",
    "resize = alt.selection_interval(bind='scales')\n",
    "\n",
    "source = author_profiles\n",
    "\n",
    "base = alt.Chart(source)\n",
    "\n",
    "labels = [str(option) + ' ' for option in options]\n",
    "\n",
    "input_dropdown = alt.binding_select(options=options + [None],\n",
    "                                    labels=labels + ['All '],\n",
    "                                    name=f'{SELECTION_LABEL} ')\n",
    "\n",
    "selection = alt.selection_point(fields=[SELECTION], \n",
    "                                bind=input_dropdown)\n",
    "\n",
    "color = alt.condition(\n",
    "    selection,\n",
    "    alt.Color(f'{SELECTION}:N').legend(None),\n",
    "    alt.value('lightgray')\n",
    ")\n",
    "\n",
    "scatter = base.mark_circle(size=75).encode(\n",
    "    x=alt.X('PCA1', title=None),\n",
    "    y=alt.Y('PCA2', title=f'PCA2 ({explained_variance[1]*100:.2f}% variance)'),\n",
    "    color=color,\n",
    "    tooltip=['author_name', 'affiliation_sinta', 'cluster', 'top_words_cluster', 'top_words_author', 'subjects', \"sinta_id\"]\n",
    ").add_params(\n",
    "    selection\n",
    ").properties(\n",
    "    height=HEIGHT,\n",
    "    width=WIDTH\n",
    ").add_selection(\n",
    "    resize\n",
    ")\n",
    "\n",
    "legend = base.mark_circle(size=75).encode(\n",
    "    alt.Y(f'{SELECTION}:N', title=SELECTION_LABEL).axis(orient='right'),\n",
    "    color=color\n",
    ")\n",
    "\n",
    "chart2 = base.mark_bar().encode(\n",
    "    x=alt.X('count()', title='Author Count'),\n",
    "    y=alt.Y('PCA2:Q', title=\"\").bin(maxbins=18),\n",
    "    color=color\n",
    ").add_params(\n",
    "    selection\n",
    ").properties(\n",
    "    height=HEIGHT,\n",
    "    width=50\n",
    ").add_selection(\n",
    "    resize\n",
    ")\n",
    "\n",
    "# Additional chart at the bottom\n",
    "chart3 = base.mark_bar().encode(\n",
    "    x=alt.X('PCA1:Q', bin=alt.Bin(maxbins=18), title=f'PCA1 ({explained_variance[0]*100:.2f}% variance)'),\n",
    "    y=alt.Y('count()', title='Author Count', scale=alt.Scale(reverse=True)),\n",
    "    color=color\n",
    ").add_params(\n",
    "    selection\n",
    ").properties(\n",
    "    height=50,\n",
    "    width=WIDTH\n",
    ").add_selection(\n",
    "    resize\n",
    ")\n",
    "\n",
    "# Vertical line at PCA1 = 0\n",
    "vertical_line = base.mark_rule(color='gray').encode(\n",
    "    x=alt.datum(0)\n",
    ").properties(\n",
    "    width=WIDTH\n",
    ")\n",
    "\n",
    "# Horizontal line at PCA2 = 0\n",
    "horizontal_line = base.mark_rule(color='gray').encode(\n",
    "    y=alt.datum(0)\n",
    ").properties(\n",
    "    height=HEIGHT\n",
    ")\n",
    "\n",
    "# Combine scatter and chart3 vertically, and chart2 and legend horizontally\n",
    "combined_chart = alt.vconcat(\n",
    "    scatter + vertical_line + horizontal_line,\n",
    "    chart3 + vertical_line\n",
    ").resolve_scale(\n",
    "    color='independent'\n",
    ") | chart2 + horizontal_line | legend\n",
    "\n",
    "# Format silhouette score to two decimal places\n",
    "silhouette_avg_formatted = f'{silhouette_avg:.2f}'\n",
    "\n",
    "# Add title to the combined chart and center it\n",
    "final_chart = combined_chart.properties(\n",
    "    title=alt.TitleParams(\n",
    "        text=f'Silhouette Score: {silhouette_avg_formatted}',\n",
    "        anchor='middle',\n",
    "        align='center'\n",
    "    )\n",
    ")\n",
    "\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4bdda-fdc9-4966-ab60-1e0dc0b5abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = Path(\"../figures/01_PCA_publication_titles.html\")\n",
    "outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "final_chart.save(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
